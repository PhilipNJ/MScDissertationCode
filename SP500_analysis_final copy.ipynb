{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S&P 500 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Import the Packages, Functions and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from EDA_functions import *\n",
    "from Baseline_functions import *\n",
    "from DQN_functions import *\n",
    "import pandas as pd\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data/SP500.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Outlier Removal \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.00037873998112499885, Std: 0.012040180200659603, Upper Limit: 0.024459100382444206, Lower Limit: -0.023701620420194205\n",
      "Number of rows outside 2 sigma range: 244\n",
      "Percentage of rows outside 2 sigma range: 4.848003179018478% \n"
     ]
    }
   ],
   "source": [
    "df['daily_return'] = df['Close'].pct_change()\n",
    "df['daily_return'] = df['daily_return'].fillna(0)\n",
    "#mean plus 3sigma value for absolute daily returns\n",
    "mean = df['daily_return'].mean()\n",
    "std = df['daily_return'].std()\n",
    "upper_limit = mean + 2*std\n",
    "lower_limit = mean - 2*std\n",
    "print(f'Mean: {mean}, Std: {std}, Upper Limit: {upper_limit}, Lower Limit: {lower_limit}')\n",
    "#number of rows that are outside the 3 sigma range\n",
    "print(f'Number of rows outside 2 sigma range: {len(df[(df[\"daily_return\"]>upper_limit) | (df[\"daily_return\"]<lower_limit)])}')\n",
    "print(f'Percentage of rows outside 2 sigma range: {len(df[(df[\"daily_return\"]>upper_limit) | (df[\"daily_return\"]<lower_limit)])/len(df)*100}% ')\n",
    "\n",
    "#if daily return is outside 3 sigma range, replace all the values with previous day's values\n",
    "for i in range(1,len(df)):\n",
    "    if df['daily_return'][i]>upper_limit or df['daily_return'][i]<lower_limit:\n",
    "        df['Close'][i] = df['Close'][i-1]\n",
    "        df['Open'][i] = df['Open'][i-1]\n",
    "        df['High'][i] = df['High'][i-1]\n",
    "        df['Low'][i] = df['Low'][i-1]\n",
    "        df['Volume'][i] = df['Volume'][i-1]\n",
    "        df['daily_return'][i] = 'NaN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_base = df[['Open','High','Low','Close','Volume']]\n",
    "#include 26 and 12 ema\n",
    "# df_base['26ema'] = df_base['Close'].ewm(span=26).mean()\n",
    "# df_base['12ema'] = df_base['Close'].ewm(span=12).mean()\n",
    "#fill na as 0\n",
    "# df_base = df_base.dropna()\n",
    "# df_base = df_base[['Open','High','Low','Close','Volume','26ema','12ema']]\n",
    "\n",
    "#first 80% of the data is train\n",
    "df_train = df_base.iloc[:int(len(df_base)*0.8)]\n",
    "#last 20% of the data is test\n",
    "df_test = df_base.iloc[int(len(df_base)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-03-31</th>\n",
       "      <td>1127.000000</td>\n",
       "      <td>1130.829956</td>\n",
       "      <td>1121.459961</td>\n",
       "      <td>1126.209961</td>\n",
       "      <td>1560700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-04-01</th>\n",
       "      <td>1126.209961</td>\n",
       "      <td>1135.670044</td>\n",
       "      <td>1126.199951</td>\n",
       "      <td>1132.170044</td>\n",
       "      <td>1560700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-04-02</th>\n",
       "      <td>1132.170044</td>\n",
       "      <td>1144.810059</td>\n",
       "      <td>1132.170044</td>\n",
       "      <td>1141.810059</td>\n",
       "      <td>1629200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-04-05</th>\n",
       "      <td>1141.810059</td>\n",
       "      <td>1150.569946</td>\n",
       "      <td>1141.640015</td>\n",
       "      <td>1150.569946</td>\n",
       "      <td>1413700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-04-06</th>\n",
       "      <td>1150.569946</td>\n",
       "      <td>1150.569946</td>\n",
       "      <td>1143.300049</td>\n",
       "      <td>1148.160034</td>\n",
       "      <td>1397700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close      Volume\n",
       "Date                                                                      \n",
       "2004-03-31  1127.000000  1130.829956  1121.459961  1126.209961  1560700000\n",
       "2004-04-01  1126.209961  1135.670044  1126.199951  1132.170044  1560700000\n",
       "2004-04-02  1132.170044  1144.810059  1132.170044  1141.810059  1629200000\n",
       "2004-04-05  1141.810059  1150.569946  1141.640015  1150.569946  1413700000\n",
       "2004-04-06  1150.569946  1150.569946  1143.300049  1148.160034  1397700000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-30</th>\n",
       "      <td>2457.770020</td>\n",
       "      <td>2571.419922</td>\n",
       "      <td>2407.530029</td>\n",
       "      <td>2475.560059</td>\n",
       "      <td>8300010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>2614.689941</td>\n",
       "      <td>2641.389893</td>\n",
       "      <td>2571.149902</td>\n",
       "      <td>2584.590088</td>\n",
       "      <td>6576210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-01</th>\n",
       "      <td>2614.689941</td>\n",
       "      <td>2641.389893</td>\n",
       "      <td>2571.149902</td>\n",
       "      <td>2584.590088</td>\n",
       "      <td>6576210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-02</th>\n",
       "      <td>2458.540039</td>\n",
       "      <td>2533.219971</td>\n",
       "      <td>2455.790039</td>\n",
       "      <td>2526.899902</td>\n",
       "      <td>6464190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-03</th>\n",
       "      <td>2514.919922</td>\n",
       "      <td>2538.179932</td>\n",
       "      <td>2459.959961</td>\n",
       "      <td>2488.649902</td>\n",
       "      <td>6096970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close      Volume\n",
       "Date                                                                      \n",
       "2020-03-30  2457.770020  2571.419922  2407.530029  2475.560059  8300010000\n",
       "2020-03-31  2614.689941  2641.389893  2571.149902  2584.590088  6576210000\n",
       "2020-04-01  2614.689941  2641.389893  2571.149902  2584.590088  6576210000\n",
       "2020-04-02  2458.540039  2533.219971  2455.790039  2526.899902  6464190000\n",
       "2020-04-03  2514.919922  2538.179932  2459.959961  2488.649902  6096970000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.head())\n",
    "\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4026, 5) (1007, 5)\n",
      "5033\n",
      "5033\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)\n",
    "print(df_train.shape[0] + df_test.shape[0])\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of states: (4000, 26, 5)\n"
     ]
    }
   ],
   "source": [
    "window_size = 26\n",
    "states = create_states(df_train, window_size)\n",
    "test_states = create_states(df_test, window_size)\n",
    "input_dim_conv = states.shape[2]\n",
    "output_dim = 3\n",
    "print(\"Shape of states:\", states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = ConvDQN(input_dim_conv, output_dim, window_size)\n",
    "memory = ReplayMemory(50000)\n",
    "agent = DQNAgent(input_dim_conv, output_dim, window_size,model, lr=0.0001, gamma=0.95, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.9995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/800, Total Reward: -410.41258374023437, Loss: 27.569311510209893\n",
      "Episode 2/800, Total Reward: -105.87585316354982, Loss: 25.077892425076048\n",
      "Episode 3/800, Total Reward: -174.76006527158205, Loss: 25.053354631031144\n",
      "Episode 4/800, Total Reward: 2.5557238469055332, Loss: 22.30231566513968\n",
      "Episode 5/800, Total Reward: -87.73936880469728, Loss: 21.532307095093156\n",
      "Episode 6/800, Total Reward: -562.980224609375, Loss: 19.228449773322854\n",
      "Episode 7/800, Total Reward: 0.0, Loss: 16.95606032087919\n",
      "Episode 8/800, Total Reward: 0.0, Loss: 13.142727182994825\n",
      "Episode 9/800, Total Reward: -456.01398193359375, Loss: 11.751624216903778\n",
      "Episode 10/800, Total Reward: 0.0, Loss: 9.474289242671619\n",
      "Episode 11/800, Total Reward: -1.1228307005467105e-20, Loss: 5.53363112738736\n",
      "Episode 12/800, Total Reward: -3.450456311203726e-05, Loss: 6.142492440547109\n",
      "Episode 13/800, Total Reward: -0.0013180280729625149, Loss: 5.6497945450827505\n",
      "Episode 14/800, Total Reward: -3.065604320471928, Loss: 5.493316477488064\n",
      "Episode 15/800, Total Reward: 0.02906480055388587, Loss: 5.589112036737037\n",
      "Episode 16/800, Total Reward: 0.026814206724397407, Loss: 5.0496613409299815\n",
      "Episode 17/800, Total Reward: -1.971502404197822e-11, Loss: 5.348945179236812\n",
      "Episode 18/800, Total Reward: 0.002686120014523826, Loss: 5.483711894679336\n",
      "Episode 19/800, Total Reward: 2.861260469136361e-07, Loss: 5.451037798681836\n",
      "Episode 20/800, Total Reward: 53.47222119140625, Loss: 4.655755279068244\n",
      "Episode 21/800, Total Reward: 5.848142573556581, Loss: 3.7890171661851615\n",
      "Episode 22/800, Total Reward: 2.5443412735719256e-06, Loss: 3.8892530619096557\n",
      "Episode 23/800, Total Reward: 5.361458159392071e-11, Loss: 4.0060033996483275\n",
      "Episode 24/800, Total Reward: 6.788669121608425e-05, Loss: 5.313853553773898\n",
      "Episode 25/800, Total Reward: -4.845000309264527e-06, Loss: 1.789390201385004\n",
      "Episode 26/800, Total Reward: -0.00024409769944496346, Loss: 5.371243654110557\n",
      "Episode 27/800, Total Reward: 6.76235885564328e-07, Loss: 4.628762220555981\n",
      "Episode 28/800, Total Reward: 0.037940877297349504, Loss: 5.860892898882279\n",
      "Episode 29/800, Total Reward: -263.06005859375, Loss: 6.415093962350922\n",
      "Episode 30/800, Total Reward: 2.4614246174842496e-07, Loss: 5.311078536639343\n",
      "Episode 31/800, Total Reward: 0.00013378703035972356, Loss: 5.0591760549574465\n",
      "Episode 32/800, Total Reward: -1.7007902542681408e-05, Loss: 5.377671595462554\n",
      "Episode 33/800, Total Reward: 3.25, Loss: 2.404300314108022\n",
      "Episode 34/800, Total Reward: 73.199951171875, Loss: 2.304273387176857\n",
      "Episode 35/800, Total Reward: -6.336291564124619e-06, Loss: 2.9562982426671898\n",
      "Episode 36/800, Total Reward: 0.0, Loss: 6.421112618457856\n",
      "Episode 37/800, Total Reward: 0.0, Loss: 6.538905782127362\n",
      "Episode 38/800, Total Reward: 3.051536557434083, Loss: 2.702767795337457\n",
      "Episode 39/800, Total Reward: 0.03957043551106462, Loss: 5.597237967522232\n",
      "Episode 40/800, Total Reward: 0.002938485179078446, Loss: 6.217883794361842\n",
      "Episode 41/800, Total Reward: -0.2842360902746675, Loss: 6.601633980434907\n",
      "Episode 42/800, Total Reward: -369.37132536621095, Loss: 6.5370630469378455\n",
      "Episode 43/800, Total Reward: 0.01641745611518205, Loss: 4.125947925904867\n",
      "Episode 44/800, Total Reward: -0.0007052271108746726, Loss: 5.178465694936168\n",
      "Episode 45/800, Total Reward: 4.200158492201533, Loss: 5.72737416148698\n",
      "Episode 46/800, Total Reward: -77.64340074267108, Loss: 5.271997140745938\n",
      "Episode 47/800, Total Reward: -1.8807872847000549, Loss: 6.039236359041374\n",
      "Episode 48/800, Total Reward: 0.005367933412762913, Loss: 3.487298687714312\n",
      "Episode 49/800, Total Reward: 24.570068359375, Loss: 3.6528260068616767\n",
      "Episode 50/800, Total Reward: -0.02007928230919398, Loss: 3.9434397270671133\n",
      "Episode 51/800, Total Reward: 0.0004272925888949071, Loss: 2.9435856287805993\n",
      "Episode 52/800, Total Reward: 3.508879484032809, Loss: 3.5933946889868627\n",
      "Episode 53/800, Total Reward: 0.1553560468315771, Loss: 3.800252370866187\n",
      "Episode 54/800, Total Reward: 0.02105383974970281, Loss: 3.9868519025197946\n",
      "Episode 55/800, Total Reward: 0.0, Loss: 3.6988883634044134\n",
      "Episode 56/800, Total Reward: 1.2558963400967211, Loss: 3.776457161199631\n",
      "Episode 57/800, Total Reward: 0.0036900641834851683, Loss: 5.629641574276056\n",
      "Episode 58/800, Total Reward: 3.12932363799907, Loss: 6.643161302770728\n",
      "Episode 59/800, Total Reward: 14.807199739370365, Loss: 4.594392789730378\n",
      "Episode 60/800, Total Reward: -64.83036556345742, Loss: 3.9967957666273466\n",
      "Episode 61/800, Total Reward: 1.2423651835210656e-05, Loss: 4.502999006476742\n",
      "Episode 62/800, Total Reward: -0.00087765099192197, Loss: 1.6875674223745964\n",
      "Episode 63/800, Total Reward: -2.5892934728489203e-14, Loss: 4.430279236198576\n",
      "Episode 64/800, Total Reward: -1.85009765625, Loss: 3.5061347960454743\n",
      "Episode 65/800, Total Reward: 0.0011957364262778674, Loss: 5.200093376933465\n",
      "Episode 66/800, Total Reward: 0.00016758644610383394, Loss: 5.26454348069397\n",
      "Episode 67/800, Total Reward: 34.67857983398438, Loss: 4.720564846572448\n",
      "Episode 68/800, Total Reward: 0.00010918256926162056, Loss: 3.5531877008510806\n",
      "Episode 69/800, Total Reward: -13.239990234375, Loss: 2.70209588668408\n",
      "Episode 70/800, Total Reward: -0.3600143499732953, Loss: 5.186474978497588\n",
      "Episode 71/800, Total Reward: -4.758326399298581e-15, Loss: 4.009047219475555\n",
      "Episode 72/800, Total Reward: -44.77001953125, Loss: 4.697558690742876\n",
      "Episode 73/800, Total Reward: 25.719970703125, Loss: 5.718093140736313\n",
      "Episode 74/800, Total Reward: 41.2099609375, Loss: 5.372107611142557\n",
      "Episode 75/800, Total Reward: 11.769775390625, Loss: 5.949078575900375\n",
      "Episode 76/800, Total Reward: 1.530029296875, Loss: 6.140633005059884\n",
      "Episode 77/800, Total Reward: -0.75, Loss: 6.250606603599115\n",
      "Episode 78/800, Total Reward: 82.530029296875, Loss: 5.965023531187967\n",
      "Episode 79/800, Total Reward: -2.5509297951240523e-14, Loss: 6.710085954616253\n",
      "Episode 80/800, Total Reward: -2.210205078125, Loss: 7.191045304730304\n",
      "Episode 81/800, Total Reward: 16.64013671875, Loss: 6.085474457323144\n",
      "Episode 82/800, Total Reward: -6.678707496981992e-08, Loss: 6.257788364719869\n",
      "Episode 83/800, Total Reward: 4.163721080274574e-17, Loss: 7.08082436520293\n",
      "Episode 84/800, Total Reward: 3.7551443197552554e-06, Loss: 7.09870033325684\n",
      "Episode 85/800, Total Reward: -1.7601373333148138e-05, Loss: 7.184504575859665\n",
      "Episode 86/800, Total Reward: 5.0794937027864326e-17, Loss: 5.519729072403555\n",
      "Episode 87/800, Total Reward: -410.41258374023437, Loss: 5.982714370110592\n",
      "Episode 88/800, Total Reward: -0.09233596759385056, Loss: 7.100864488245856\n",
      "Episode 89/800, Total Reward: -0.29758158434239024, Loss: 6.248577055052671\n",
      "Episode 90/800, Total Reward: -0.3265684119274003, Loss: 5.517599835773707\n",
      "Episode 91/800, Total Reward: -5.986997516624083e-58, Loss: 7.088125368285524\n",
      "Episode 92/800, Total Reward: -3.9950979879112866e-09, Loss: 9.203242782636973\n",
      "Episode 93/800, Total Reward: -7.855771958108697e-06, Loss: 6.381545401927761\n",
      "Episode 94/800, Total Reward: 31.489990234375, Loss: 5.325079904485611\n",
      "Episode 95/800, Total Reward: 39.780029296875, Loss: 5.0899849657022065\n",
      "Episode 96/800, Total Reward: 2.786557106840147, Loss: 9.215697869920522\n",
      "Episode 97/800, Total Reward: -4.350835938055864e-10, Loss: 4.647408608540996\n",
      "Episode 98/800, Total Reward: -21.349853515625, Loss: 5.394944067718828\n",
      "Episode 99/800, Total Reward: 77.2099609375, Loss: 6.509403664856683\n",
      "Episode 100/800, Total Reward: 0.8783172450427195, Loss: 6.236551007019367\n",
      "Episode 101/800, Total Reward: 6.563752278550635e-07, Loss: 5.218252190055184\n",
      "Episode 102/800, Total Reward: 6.260009765625, Loss: 5.753446803228555\n",
      "Episode 103/800, Total Reward: -0.027748354840711514, Loss: 5.119523728494023\n",
      "Episode 104/800, Total Reward: 0.19919190291622071, Loss: 5.712456497614533\n",
      "Episode 105/800, Total Reward: 9.770502117583623, Loss: 5.320883100031279\n",
      "Episode 106/800, Total Reward: 0.00021183876428285152, Loss: 6.042549541146515\n",
      "Episode 107/800, Total Reward: 0.4820061805103422, Loss: 6.586045198852986\n",
      "Episode 108/800, Total Reward: 37.679931640625, Loss: 4.530705611046412\n",
      "Episode 109/800, Total Reward: -6.349853515625, Loss: 5.423099371060574\n",
      "Episode 110/800, Total Reward: 0.0, Loss: 5.387883974535128\n",
      "Episode 111/800, Total Reward: 0.0, Loss: 5.245366558464113\n",
      "Episode 112/800, Total Reward: -12.39990234375, Loss: 5.41725106643374\n",
      "Episode 113/800, Total Reward: 9.199951171875, Loss: 8.256292693986058\n",
      "Episode 114/800, Total Reward: 21.35009765625, Loss: 8.139744030874741\n",
      "Episode 115/800, Total Reward: 6.4599609375, Loss: 5.968766251917053\n",
      "Episode 116/800, Total Reward: 38.6298828125, Loss: 6.58740288069058\n",
      "Episode 117/800, Total Reward: 7.010009765625, Loss: 5.855335877530373\n",
      "Episode 118/800, Total Reward: 7.139892578125, Loss: 6.630652062360535\n",
      "Episode 119/800, Total Reward: 18.260009765625, Loss: 6.9390458607501575\n",
      "Episode 120/800, Total Reward: -221.360107421875, Loss: 7.659963704590781\n",
      "Episode 121/800, Total Reward: -0.64990234375, Loss: 6.861146461971483\n",
      "Episode 122/800, Total Reward: 51.419921875, Loss: 7.982717788805249\n",
      "Episode 123/800, Total Reward: 33.669921875, Loss: 8.301435202401862\n",
      "Episode 124/800, Total Reward: -8.60463811163868e-05, Loss: 7.040717662095198\n",
      "Episode 125/800, Total Reward: 0.004362178691239352, Loss: 7.274075367686759\n",
      "Episode 126/800, Total Reward: -5.295868388517045, Loss: 6.82199578141664\n",
      "Episode 127/800, Total Reward: 0.720643726975342, Loss: 6.474500296930245\n",
      "Episode 128/800, Total Reward: 1.1987119995117188, Loss: 7.129908398574487\n",
      "Episode 129/800, Total Reward: 5.230409565901925e-08, Loss: 7.268694846940014\n",
      "Episode 130/800, Total Reward: 0.549768323621503, Loss: 6.5519321972731355\n",
      "Episode 131/800, Total Reward: 0.0006031282018016474, Loss: 5.724071071026036\n",
      "Episode 132/800, Total Reward: 0.001359074075714974, Loss: 6.383363831290412\n",
      "Episode 133/800, Total Reward: 3.773845975518442, Loss: 6.079465615161045\n",
      "Episode 134/800, Total Reward: -456.01398193359375, Loss: 5.679413652006745\n",
      "Episode 135/800, Total Reward: -5.1836250579734645e-05, Loss: 5.78508537428233\n",
      "Episode 136/800, Total Reward: -0.006194655961731994, Loss: 3.5640035356846047\n",
      "Episode 137/800, Total Reward: 0.005348600510862194, Loss: 6.317099462937044\n",
      "Episode 138/800, Total Reward: 0.00016011208247101945, Loss: 3.5926883111954804\n",
      "Episode 139/800, Total Reward: -25.1298828125, Loss: 4.126655402789818\n",
      "Episode 140/800, Total Reward: 52.64990234375, Loss: 5.520924030600007\n",
      "Episode 141/800, Total Reward: 43.679931640625, Loss: 5.248601389424533\n",
      "Episode 142/800, Total Reward: 3.3844704935612343e-10, Loss: 5.387606440127243\n",
      "Episode 143/800, Total Reward: -456.01398193359375, Loss: 5.371181731924595\n",
      "Episode 144/800, Total Reward: 0.18722469546133208, Loss: 4.0073304109033385\n",
      "Episode 145/800, Total Reward: -4.476831701372181e-31, Loss: 5.95294136284165\n",
      "Episode 146/800, Total Reward: 0.045585484938201526, Loss: 4.829409998980797\n",
      "Episode 147/800, Total Reward: -0.0009718325176951429, Loss: 6.184143164942514\n",
      "Episode 148/800, Total Reward: 0.02985024026564138, Loss: 5.091109568036721\n",
      "Episode 149/800, Total Reward: -562.980224609375, Loss: 9.219440442016984\n",
      "Episode 150/800, Total Reward: 51.7099609375, Loss: 5.161593977833073\n",
      "Episode 151/800, Total Reward: 3.188562157725961e-06, Loss: 4.847686333327054\n",
      "Episode 152/800, Total Reward: 1.0178365453054183e-09, Loss: 9.25094806228493\n",
      "Episode 153/800, Total Reward: 0.0002170617123435201, Loss: 5.890169767043201\n",
      "Episode 154/800, Total Reward: -7.50462379740188e-07, Loss: 6.251122351369749\n",
      "Episode 155/800, Total Reward: 9.642540237890627, Loss: 9.227272000769979\n",
      "Episode 156/800, Total Reward: -0.057655548953262324, Loss: 4.664440058974904\n",
      "Episode 157/800, Total Reward: 0.029255865543368807, Loss: 5.667258658713604\n",
      "Episode 158/800, Total Reward: -0.02818220542423458, Loss: 5.993982127294942\n",
      "Episode 159/800, Total Reward: -6.577406886756928e-20, Loss: 4.8163642072330095\n",
      "Episode 160/800, Total Reward: 1.1385763934677278, Loss: 6.05076526618249\n",
      "Episode 161/800, Total Reward: 27.97998046875, Loss: 5.7276664167059455\n",
      "Episode 162/800, Total Reward: 0.04790625402470894, Loss: 5.042402846374334\n",
      "Episode 163/800, Total Reward: -66.110107421875, Loss: 5.603326969744979\n",
      "Episode 164/800, Total Reward: -3.1445687138101066, Loss: 6.2733503200389515\n",
      "Episode 165/800, Total Reward: 0.23993023005232852, Loss: 5.93731257238865\n",
      "Episode 166/800, Total Reward: 2.5368280381086817e-20, Loss: 5.264938055232194\n",
      "Episode 167/800, Total Reward: -4.810201420620997e-52, Loss: 5.665319839974229\n",
      "Episode 168/800, Total Reward: 2.1170480792573737e-11, Loss: 3.9921196103871783\n",
      "Episode 169/800, Total Reward: 0.00016406535510001666, Loss: 5.139531121832918\n",
      "Episode 170/800, Total Reward: 0.026734169613934565, Loss: 3.0360421130194517\n",
      "Episode 171/800, Total Reward: 0.001727817319763653, Loss: 5.440783751963951\n",
      "Episode 172/800, Total Reward: -9.102589622924867e-13, Loss: 2.999827727042319\n",
      "Episode 173/800, Total Reward: 0.0002373937541081033, Loss: 5.359638695286139\n",
      "Episode 174/800, Total Reward: -19.449951171875, Loss: 3.0758702854299282\n",
      "Episode 175/800, Total Reward: -5.85009765625, Loss: 4.588818658557948\n",
      "Episode 176/800, Total Reward: -5.639892578125, Loss: 2.4982345228054217\n",
      "Episode 177/800, Total Reward: -47.830078125, Loss: 5.687389482045092\n",
      "Episode 178/800, Total Reward: 25.409912109375, Loss: 3.959401680518811\n",
      "Episode 179/800, Total Reward: 40.159912109375, Loss: 5.748946979938689\n",
      "Episode 180/800, Total Reward: 36.989990234375, Loss: 6.642828842130249\n",
      "Episode 181/800, Total Reward: -221.360107421875, Loss: 6.872211712845066\n",
      "Episode 182/800, Total Reward: -54.280029296875, Loss: 6.600144829140465\n",
      "Episode 183/800, Total Reward: 23.760009765625, Loss: 6.426534874703108\n",
      "Episode 184/800, Total Reward: -4.929931640625, Loss: 7.064612323989124\n",
      "Episode 185/800, Total Reward: 14.119873046875, Loss: 7.046578644142886\n",
      "Episode 186/800, Total Reward: 44.760009765625, Loss: 7.7697144914244864\n",
      "Episode 187/800, Total Reward: -1.6190470864775737e-06, Loss: 7.765719198712161\n",
      "Episode 188/800, Total Reward: 6.556679999247578e-19, Loss: 6.0446893855072945\n",
      "Episode 189/800, Total Reward: -0.521468900623293, Loss: 7.046403319949409\n",
      "Episode 190/800, Total Reward: 4.422246930366791, Loss: 7.223432787800224\n",
      "Episode 191/800, Total Reward: 0.010561448480362775, Loss: 6.465076180697607\n",
      "Episode 192/800, Total Reward: -42.0710350263794, Loss: 6.01685554501026\n",
      "Episode 193/800, Total Reward: 108.830078125, Loss: 6.184668875929648\n",
      "Episode 194/800, Total Reward: 0.39627652803059676, Loss: 5.91777983460103\n",
      "Episode 195/800, Total Reward: 3.9361525531638244, Loss: 6.110190131589691\n",
      "Episode 196/800, Total Reward: 0.11613648664696324, Loss: 5.443414121491547\n",
      "Episode 197/800, Total Reward: 1.2435904804740276, Loss: 3.881927661721479\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_train = train_agent(agent, states, 800, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_train.to_csv('SP500/log_train_CNN_updated_reward_800ep.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#save the model\n",
    "torch.save(agent.model.state_dict(), 'SP500/DQN_CNN_updated_reward_800ep.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training without Hold penalty\")\n",
    "log_train_no_hold = train_agent_hold(agent, states, 800, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train_no_hold.to_csv('SP500/log_train_CNN_updated_reward_MA_no_hold_800ep.csv', index=False)\n",
    "\n",
    "#save the model\n",
    "torch.save(agent.model.state_dict(), 'SP500/DQN_CNN_updated_reward_MA_no_hold_800ep.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Evaluating and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_train = pd.read_csv('SP500/log_train_CNN_updated_reward_MA_800ep.csv')\n",
    "log_train_no_hold = pd.read_csv('SP500/log_train_CNN_updated_reward_MA_no_hold_800ep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_train.rename(columns={'Reward':'Training_reward'}, inplace=True)\n",
    "log_train_no_hold.rename(columns={'Reward':'Training_reward_no_hold'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "reward =[]\n",
    "for i in range(1,log_train['Episode'].max()+1):\n",
    "    last_episode = log_train[log_train['Episode'] == i]\n",
    "    last_episode.reset_index(drop=True, inplace=True)\n",
    "    last_episode['Close'] = last_episode['Price'].to_list()\n",
    "    reward.append(list(capital_calculation(last_episode,'Action'))[-1]-100);\n",
    "\n",
    "reward_no_hold =[]\n",
    "for i in range(1,log_train_no_hold['Episode'].max()+1):\n",
    "    last_episode = log_train_no_hold[log_train_no_hold['Episode'] == i]\n",
    "    last_episode.reset_index(drop=True, inplace=True)\n",
    "    last_episode['Close'] = last_episode['Price'].to_list()\n",
    "    reward_no_hold.append(list(capital_calculation(last_episode,'Action'))[-1]-100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train['Reward'] = log_train['Episode'].apply(lambda x: reward[x-1])\n",
    "log_train_no_hold['Reward'] = log_train_no_hold['Episode'].apply(lambda x: reward_no_hold[x-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_filter(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_filter(reward_no_hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training(log_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training(log_train_no_hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "action_episode_df = create_action_episode_df(log_train)\n",
    "action_episode_df_no_hold = create_action_episode_df(log_train_no_hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "action_episode_df = action_episode_df.apply(pd.Series.value_counts).transpose().reset_index()\n",
    "action_episode_df_no_hold = action_episode_df_no_hold.apply(pd.Series.value_counts).transpose().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#get value counts of all columns in the DataFrame\n",
    "action_episode_df[['Buy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_episode_df_no_hold[['Buy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Initialize the agent\n",
    "test_state_size = test_states.shape[2]\n",
    "action_size = 3\n",
    "model = ConvDQN(input_dim_conv, output_dim, window_size)\n",
    "agent = DQNAgent(test_state_size, output_dim, window_size,model, lr=0.0001, gamma=0.95, epsilon=0, epsilon_min=0, epsilon_decay=0.9995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_state_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_path = 'SP500/DQN_CNN_updated_reward_MA_800ep.pth'\n",
    "agent.model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "agent.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_log = evaluate_agent(agent, test_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_log['Close'] = evaluation_log['Price']\n",
    "evaluation_log['Capital'] = capital_calculation(evaluation_log, 'Action')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dual_axis(evaluation_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Return without DQN: {(evaluation_log['Close'].iloc[-1] - evaluation_log['Close'].iloc[0])/evaluation_log['Close'].iloc[0] }%\")\n",
    "print(f\"Return with DQN: {(evaluation_log['Capital'].iloc[-1] - 100)/100 }%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = create_states(df_base, window_size)\n",
    "all_states_eval = evaluate_agent(agent, all_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states_eval['Close'] = all_states_eval['Price']\n",
    "all_states_eval['Capital'] = capital_calculation(all_states_eval, 'Action')\n",
    "all_states_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Return without trading: {(all_states_eval[\"Close\"].iloc[-1] - all_states_eval[\"Close\"].iloc[0])/all_states_eval[\"Close\"].iloc[0]}')\n",
    "print(f\"Return on Investment: {(all_states_eval['Capital'].iloc[-1] - 100)/100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dual_axis(all_states_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_log['Date']= df_test.tail(evaluation_log.shape[0]).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
