{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S&P 500 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Packages, Functions and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from EDA_functions import EDA, normality_check,stationarity_check,decomposition_plot,daily_returns\n",
    "from Baseline_functions import capital_calculation, calculate_macd_signals, profit_trades, loss_trades\n",
    "from DQN_functions import create_states, ReplayMemory, DQNAgent,train_agent,evaluate_agent, ConvDQN,plot_training,create_action_episode_df\n",
    "import pandas as pd\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data/SP500.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition_plot(df,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationarity_check(df,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normality_check(df,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After 1st Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition_plot(df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationarity_check(df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normality_check(df,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Check\n",
    "\n",
    "Since price gradually increases, it does not make sense to use traditional outlier checking methods. Therefore we calculate the daily change and then the outliers in those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_returns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Removal \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['daily_return'] = df['Close'].pct_change()\n",
    "df['daily_return'] = df['daily_return'].fillna(0)\n",
    "#mean plus 3sigma value for absolute daily returns\n",
    "mean = df['daily_return'].mean()\n",
    "std = df['daily_return'].std()\n",
    "upper_limit = mean + 2*std\n",
    "lower_limit = mean - 2*std\n",
    "print(f'Mean: {mean}, Std: {std}, Upper Limit: {upper_limit}, Lower Limit: {lower_limit}')\n",
    "#number of rows that are outside the 3 sigma range\n",
    "print(f'Number of rows outside 3 sigma range: {len(df[(df[\"daily_return\"]>upper_limit) | (df[\"daily_return\"]<lower_limit)])}')\n",
    "print(f'Percentage of rows outside 3 sigma range: {len(df[(df[\"daily_return\"]>upper_limit) | (df[\"daily_return\"]<lower_limit)])/len(df)*100}% ')\n",
    "\n",
    "#if daily return is outside 3 sigma range, replace all the values with previous day's values\n",
    "for i in range(1,len(df)):\n",
    "    if df['daily_return'][i]>upper_limit or df['daily_return'][i]<lower_limit:\n",
    "        df['Close'][i] = df['Close'][i-1]\n",
    "        df['Open'][i] = df['Open'][i-1]\n",
    "        df['High'][i] = df['High'][i-1]\n",
    "        df['Low'][i] = df['Low'][i-1]\n",
    "        df['Volume'][i] = df['Volume'][i-1]\n",
    "        df['daily_return'][i] = 'NaN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = calculate_macd_signals(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = profit_trades(df_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = loss_trades(df_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = df[['Open','High','Low','Close','Volume']]\n",
    "\n",
    "#first 80% of the data is train\n",
    "df_train = df_base.iloc[:int(len(df_base)*0.8)]\n",
    "#last 20% of the data is test\n",
    "df_test = df_base.iloc[int(len(df_base)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min-max scaling manually\n",
    "\n",
    "df_train_scaled = (df_train - df_train.min())/(df_train.max()-df_train.min())\n",
    "df_test_scaled = (df_test - df_train.min())/(df_train.max()-df_train.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train.head())\n",
    "\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape, df_test.shape)\n",
    "print(df_train.shape[0] + df_test.shape[0])\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 9\n",
    "states = create_states(df_train_scaled, window_size)\n",
    "test_states = create_states(df_test_scaled, window_size)\n",
    "input_dim_conv = states.shape[2]\n",
    "output_dim = 3\n",
    "print(\"Shape of states:\", states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvDQN(input_dim_conv, output_dim, window_size)\n",
    "memory = ReplayMemory(50000)\n",
    "agent = DQNAgent(input_dim_conv, output_dim, window_size, lr=0.0001, gamma=0.95, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "log_train = train_agent(agent, states, 350, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train.to_csv('SP500/log_train_CNN_adjusted_lr_hyp_tuned_350_ep_mu2sigma.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "torch.save(agent.model.state_dict(), 'SP500/dqn_model_log_train_CNN_adjusted_lr_hyp_tuned.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train = pd.read_csv('SP500/log_train_CNN_adjusted learning rate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training(log_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_episode = log_train[log_train['Episode'] == log_train['Episode'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_episode.reset_index(drop=True, inplace=True)\n",
    "last_episode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_episode['Close'] = last_episode['Price'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_episode['Capital_DQN'] = capital_calculation(last_episode,'Action')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_episode_df = create_action_episode_df(log_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get value counts of all columns in the DataFrame\n",
    "action_episode_df.apply(pd.Series.value_counts).transpose()[['Buy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the agent\n",
    "test_state_size = test_states.shape[1] * test_states.shape[2]\n",
    "action_size = 3\n",
    "agent = DQNAgent(state_size, action_size, lr=0.00001, gamma=0.95, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_state_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'SP500/dqn_modelSP500_CNN_500_wo_outliers_hyp_tuned.pth'\n",
    "agent.model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "agent.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "total_reward, actions = evaluate_agent(agent, test_states)\n",
    "print(f\"Total Reward on Test Data: {total_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optimize hyperparameters with Optuna\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=100)\n",
    "\n",
    "# print(f\"Best hyperparameters: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
